{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12974200,"sourceType":"datasetVersion","datasetId":8211716}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### ONLY FOR TESTING PURPOSES, CANNOT BE USED IN PRODUCTION\n##### This is a Kaggle Jupyter Notebook, therefore some restrictions apply when running Airflow in this environment. For example, the scheduling functions are restricted => we tested the execution of the DAG one time instead of scheduling it.\n\n##### This script connects to the API Football data to fetch the Premier League standings results in a json file (Extract). Then, the useful data is arranged into a list of tuples (Transform). Finally, the script connects to Azure Database for MySQL Server to update a table with the standings results (Load).\n","metadata":{}},{"cell_type":"code","source":"# install mysql-connector-python package to connect with MySQL\n!pip install mysql-connector-python \n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-17T02:01:21.436433Z","iopub.execute_input":"2025-09-17T02:01:21.436810Z","iopub.status.idle":"2025-09-17T02:01:27.348498Z","shell.execute_reply.started":"2025-09-17T02:01:21.436776Z","shell.execute_reply":"2025-09-17T02:01:27.347223Z"}},"outputs":[{"name":"stdout","text":"Collecting mysql-connector-python\n  Downloading mysql_connector_python-9.4.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (7.3 kB)\nDownloading mysql_connector_python-9.4.0-cp311-cp311-manylinux_2_28_x86_64.whl (33.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.9/33.9 MB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: mysql-connector-python\nSuccessfully installed mysql-connector-python-9.4.0\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"# Orchestration - install apache Airflow\n\n!pip install apache-airflow","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-17T01:54:32.203532Z","iopub.execute_input":"2025-09-17T01:54:32.203863Z","iopub.status.idle":"2025-09-17T01:55:15.727119Z","shell.execute_reply.started":"2025-09-17T01:54:32.203835Z","shell.execute_reply":"2025-09-17T01:55:15.726039Z"}},"outputs":[{"name":"stdout","text":"Collecting apache-airflow\n  Downloading apache_airflow-3.0.6-py3-none-any.whl.metadata (32 kB)\nCollecting apache-airflow-core==3.0.6 (from apache-airflow)\n  Downloading apache_airflow_core-3.0.6-py3-none-any.whl.metadata (7.4 kB)\nCollecting apache-airflow-task-sdk<1.1.0,>=1.0.6 (from apache-airflow)\n  Downloading apache_airflow_task_sdk-1.0.6-py3-none-any.whl.metadata (3.8 kB)\nCollecting a2wsgi>=1.10.8 (from apache-airflow-core==3.0.6->apache-airflow)\n  Downloading a2wsgi-1.10.10-py3-none-any.whl.metadata (4.0 kB)\nRequirement already satisfied: aiosqlite>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from apache-airflow-core==3.0.6->apache-airflow) (0.21.0)\nRequirement already satisfied: alembic<2.0,>=1.13.1 in /usr/local/lib/python3.11/dist-packages (from apache-airflow-core==3.0.6->apache-airflow) (1.16.2)\nCollecting apache-airflow-providers-common-compat>=1.6.0 (from apache-airflow-core==3.0.6->apache-airflow)\n  Downloading apache_airflow_providers_common_compat-1.7.3-py3-none-any.whl.metadata (5.3 kB)\nCollecting apache-airflow-providers-common-io>=1.5.3 (from apache-airflow-core==3.0.6->apache-airflow)\n  Downloading apache_airflow_providers_common_io-1.6.2-py3-none-any.whl.metadata (5.3 kB)\nCollecting apache-airflow-providers-common-sql>=1.26.0 (from apache-airflow-core==3.0.6->apache-airflow)\n  Downloading apache_airflow_providers_common_sql-1.28.0-py3-none-any.whl.metadata (5.5 kB)\nCollecting apache-airflow-providers-smtp>=2.0.2 (from apache-airflow-core==3.0.6->apache-airflow)\n  Downloading apache_airflow_providers_smtp-2.2.1-py3-none-any.whl.metadata (5.1 kB)\nCollecting apache-airflow-providers-standard>=0.4.0 (from apache-airflow-core==3.0.6->apache-airflow)\n  Downloading apache_airflow_providers_standard-1.7.0-py3-none-any.whl.metadata (3.8 kB)\nCollecting argcomplete>=1.10 (from apache-airflow-core==3.0.6->apache-airflow)\n  Downloading argcomplete-3.6.2-py3-none-any.whl.metadata (16 kB)\nCollecting asgiref>=2.3.0 (from apache-airflow-core==3.0.6->apache-airflow)\n  Downloading asgiref-3.9.1-py3-none-any.whl.metadata (9.3 kB)\nRequirement already satisfied: attrs!=25.2.0,>=22.1.0 in /usr/local/lib/python3.11/dist-packages (from apache-airflow-core==3.0.6->apache-airflow) (25.3.0)\nCollecting cadwyn>=5.2.1 (from apache-airflow-core==3.0.6->apache-airflow)\n  Downloading cadwyn-5.4.4-py3-none-any.whl.metadata (5.1 kB)\nRequirement already satisfied: colorlog>=6.8.2 in /usr/local/lib/python3.11/dist-packages (from apache-airflow-core==3.0.6->apache-airflow) (6.9.0)\nCollecting cron-descriptor>=1.2.24 (from apache-airflow-core==3.0.6->apache-airflow)\n  Downloading cron_descriptor-2.0.6-py3-none-any.whl.metadata (8.1 kB)\nCollecting croniter>=2.0.2 (from apache-airflow-core==3.0.6->apache-airflow)\n  Downloading croniter-6.0.0-py2.py3-none-any.whl.metadata (32 kB)\nRequirement already satisfied: cryptography>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from apache-airflow-core==3.0.6->apache-airflow) (44.0.3)\nRequirement already satisfied: deprecated>=1.2.13 in /usr/local/lib/python3.11/dist-packages (from apache-airflow-core==3.0.6->apache-airflow) (1.2.18)\nRequirement already satisfied: dill>=0.2.2 in /usr/local/lib/python3.11/dist-packages (from apache-airflow-core==3.0.6->apache-airflow) (0.3.8)\nRequirement already satisfied: fastapi!=0.115.10,>=0.115.0 in /usr/local/lib/python3.11/dist-packages (from fastapi[standard]!=0.115.10,>=0.115.0->apache-airflow-core==3.0.6->apache-airflow) (0.115.13)\nRequirement already satisfied: flask>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from apache-airflow-core==3.0.6->apache-airflow) (3.1.1)\nCollecting gunicorn>=20.1.0 (from apache-airflow-core==3.0.6->apache-airflow)\n  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\nRequirement already satisfied: httpx>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from apache-airflow-core==3.0.6->apache-airflow) (0.28.1)\nRequirement already satisfied: importlib-metadata>=6.5 in /usr/local/lib/python3.11/dist-packages (from apache-airflow-core==3.0.6->apache-airflow) (8.7.0)\nRequirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.11/dist-packages (from apache-airflow-core==3.0.6->apache-airflow) (2.2.0)\nRequirement already satisfied: jinja2>=3.1.5 in /usr/local/lib/python3.11/dist-packages (from apache-airflow-core==3.0.6->apache-airflow) (3.1.6)\nRequirement already satisfied: jsonschema>=4.19.1 in /usr/local/lib/python3.11/dist-packages (from apache-airflow-core==3.0.6->apache-airflow) (4.24.0)\nCollecting lazy-object-proxy>=1.2.0 (from apache-airflow-core==3.0.6->apache-airflow)\n  Downloading lazy_object_proxy-1.12.0-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (5.1 kB)\nCollecting libcst>=1.1.0 (from apache-airflow-core==3.0.6->apache-airflow)\n  Downloading libcst-1.8.4-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (15 kB)\nRequirement already satisfied: linkify-it-py>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from apache-airflow-core==3.0.6->apache-airflow) (2.0.3)\nCollecting lockfile>=0.12.2 (from apache-airflow-core==3.0.6->apache-airflow)\n  Downloading lockfile-0.12.2-py2.py3-none-any.whl.metadata (2.4 kB)\nCollecting methodtools>=0.4.7 (from apache-airflow-core==3.0.6->apache-airflow)\n  Downloading methodtools-0.4.7-py2.py3-none-any.whl.metadata (3.0 kB)\nCollecting opentelemetry-api>=1.26.0 (from apache-airflow-core==3.0.6->apache-airflow)\n  Downloading opentelemetry_api-1.37.0-py3-none-any.whl.metadata (1.5 kB)\nCollecting opentelemetry-exporter-otlp>=1.26.0 (from apache-airflow-core==3.0.6->apache-airflow)\n  Downloading opentelemetry_exporter_otlp-1.37.0-py3-none-any.whl.metadata (2.4 kB)\nRequirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from apache-airflow-core==3.0.6->apache-airflow) (25.0)\nCollecting pathspec>=0.9.0 (from apache-airflow-core==3.0.6->apache-airflow)\n  Downloading pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\nCollecting pendulum<4.0,>=2.1.2 (from apache-airflow-core==3.0.6->apache-airflow)\n  Downloading pendulum-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\nRequirement already satisfied: pluggy>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from apache-airflow-core==3.0.6->apache-airflow) (1.6.0)\nRequirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from apache-airflow-core==3.0.6->apache-airflow) (7.0.0)\nRequirement already satisfied: pydantic>=2.11.0 in /usr/local/lib/python3.11/dist-packages (from apache-airflow-core==3.0.6->apache-airflow) (2.11.7)\nRequirement already satisfied: pygments!=2.19.0,>=2.0.1 in /usr/local/lib/python3.11/dist-packages (from apache-airflow-core==3.0.6->apache-airflow) (2.19.2)\nRequirement already satisfied: pyjwt>=2.10.0 in /usr/local/lib/python3.11/dist-packages (from apache-airflow-core==3.0.6->apache-airflow) (2.10.1)\nCollecting python-daemon>=3.0.0 (from apache-airflow-core==3.0.6->apache-airflow)\n  Downloading python_daemon-3.1.2-py3-none-any.whl.metadata (4.8 kB)\nRequirement already satisfied: python-dateutil>=2.7.0 in /usr/local/lib/python3.11/dist-packages (from apache-airflow-core==3.0.6->apache-airflow) (2.9.0.post0)\nRequirement already satisfied: python-slugify>=5.0 in /usr/local/lib/python3.11/dist-packages (from apache-airflow-core==3.0.6->apache-airflow) (8.0.4)\nRequirement already satisfied: requests<3,>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from apache-airflow-core==3.0.6->apache-airflow) (2.32.4)\nCollecting rich-argparse>=1.0.0 (from apache-airflow-core==3.0.6->apache-airflow)\n  Downloading rich_argparse-1.7.1-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: rich>=13.6.0 in /usr/local/lib/python3.11/dist-packages (from apache-airflow-core==3.0.6->apache-airflow) (14.0.0)\nRequirement already satisfied: setproctitle>=1.3.3 in /usr/local/lib/python3.11/dist-packages (from apache-airflow-core==3.0.6->apache-airflow) (1.3.6)\nCollecting sqlalchemy-jsonfield>=1.0 (from apache-airflow-core==3.0.6->apache-airflow)\n  Downloading SQLAlchemy_JSONField-1.0.2-py3-none-any.whl.metadata (5.2 kB)\nCollecting sqlalchemy-utils>=0.41.2 (from apache-airflow-core==3.0.6->apache-airflow)\n  Downloading sqlalchemy_utils-0.42.0-py3-none-any.whl.metadata (4.6 kB)\nCollecting sqlalchemy<2.0,>=1.4.49 (from sqlalchemy[asyncio]<2.0,>=1.4.49->apache-airflow-core==3.0.6->apache-airflow)\n  Downloading SQLAlchemy-1.4.54-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\nCollecting svcs>=25.1.0 (from apache-airflow-core==3.0.6->apache-airflow)\n  Downloading svcs-25.1.0-py3-none-any.whl.metadata (7.6 kB)\nRequirement already satisfied: tabulate>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from apache-airflow-core==3.0.6->apache-airflow) (0.9.0)\nRequirement already satisfied: tenacity!=8.2.0,>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from apache-airflow-core==3.0.6->apache-airflow) (8.5.0)\nRequirement already satisfied: termcolor>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from apache-airflow-core==3.0.6->apache-airflow) (3.1.0)\nCollecting typing-extensions!=4.14.0 (from apache-airflow-core==3.0.6->apache-airflow)\n  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\nCollecting universal-pathlib!=0.2.4,>=0.2.2 (from apache-airflow-core==3.0.6->apache-airflow)\n  Downloading universal_pathlib-0.2.6-py3-none-any.whl.metadata (25 kB)\nCollecting uuid6>=2024.7.10 (from apache-airflow-core==3.0.6->apache-airflow)\n  Downloading uuid6-2025.0.1-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: fsspec>=2023.10.0 in /usr/local/lib/python3.11/dist-packages (from apache-airflow-task-sdk<1.1.0,>=1.0.6->apache-airflow) (2025.5.1)\nCollecting msgspec>=0.19.0 (from apache-airflow-task-sdk<1.1.0,>=1.0.6->apache-airflow)\n  Downloading msgspec-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\nCollecting retryhttp!=1.3.0,>=1.2.0 (from apache-airflow-task-sdk<1.1.0,>=1.0.6->apache-airflow)\n  Downloading retryhttp-1.3.3-py3-none-any.whl.metadata (17 kB)\nCollecting structlog>=25.4.0 (from apache-airflow-task-sdk<1.1.0,>=1.0.6->apache-airflow)\n  Downloading structlog-25.4.0-py3-none-any.whl.metadata (7.6 kB)\nRequirement already satisfied: Mako in /usr/local/lib/python3.11/dist-packages (from alembic<2.0,>=1.13.1->apache-airflow-core==3.0.6->apache-airflow) (1.3.10)\nRequirement already satisfied: sqlparse>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from apache-airflow-providers-common-sql>=1.26.0->apache-airflow-core==3.0.6->apache-airflow) (0.5.3)\nRequirement already satisfied: more-itertools>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from apache-airflow-providers-common-sql>=1.26.0->apache-airflow-core==3.0.6->apache-airflow) (10.7.0)\nRequirement already satisfied: starlette>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from cadwyn>=5.2.1->apache-airflow-core==3.0.6->apache-airflow) (0.46.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from cadwyn>=5.2.1->apache-airflow-core==3.0.6->apache-airflow) (0.4.1)\nRequirement already satisfied: pytz>2021.1 in /usr/local/lib/python3.11/dist-packages (from croniter>=2.0.2->apache-airflow-core==3.0.6->apache-airflow) (2025.2)\nRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=41.0.0->apache-airflow-core==3.0.6->apache-airflow) (1.17.1)\nRequirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated>=1.2.13->apache-airflow-core==3.0.6->apache-airflow) (1.17.2)\nCollecting fastapi-cli>=0.0.5 (from fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]!=0.115.10,>=0.115.0->apache-airflow-core==3.0.6->apache-airflow)\n  Downloading fastapi_cli-0.0.11-py3-none-any.whl.metadata (6.3 kB)\nRequirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from fastapi[standard]!=0.115.10,>=0.115.0->apache-airflow-core==3.0.6->apache-airflow) (0.0.20)\nRequirement already satisfied: email-validator>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from fastapi[standard]!=0.115.10,>=0.115.0->apache-airflow-core==3.0.6->apache-airflow) (2.2.0)\nRequirement already satisfied: uvicorn>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]!=0.115.10,>=0.115.0->apache-airflow-core==3.0.6->apache-airflow) (0.34.3)\nRequirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from flask>=2.1.1->apache-airflow-core==3.0.6->apache-airflow) (1.9.0)\nRequirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask>=2.1.1->apache-airflow-core==3.0.6->apache-airflow) (8.2.1)\nRequirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from flask>=2.1.1->apache-airflow-core==3.0.6->apache-airflow) (3.0.2)\nRequirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from flask>=2.1.1->apache-airflow-core==3.0.6->apache-airflow) (3.1.3)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->apache-airflow-core==3.0.6->apache-airflow) (4.9.0)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->apache-airflow-core==3.0.6->apache-airflow) (2025.6.15)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->apache-airflow-core==3.0.6->apache-airflow) (1.0.9)\nRequirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->apache-airflow-core==3.0.6->apache-airflow) (3.10)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.0->apache-airflow-core==3.0.6->apache-airflow) (0.16.0)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata>=6.5->apache-airflow-core==3.0.6->apache-airflow) (3.23.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.1->apache-airflow-core==3.0.6->apache-airflow) (2025.4.1)\nRequirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.1->apache-airflow-core==3.0.6->apache-airflow) (0.36.2)\nRequirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.1->apache-airflow-core==3.0.6->apache-airflow) (0.25.1)\nRequirement already satisfied: pyyaml>=5.2 in /usr/local/lib/python3.11/dist-packages (from libcst>=1.1.0->apache-airflow-core==3.0.6->apache-airflow) (6.0.2)\nRequirement already satisfied: uc-micro-py in /usr/local/lib/python3.11/dist-packages (from linkify-it-py>=2.0.0->apache-airflow-core==3.0.6->apache-airflow) (1.0.3)\nCollecting wirerope>=0.4.7 (from methodtools>=0.4.7->apache-airflow-core==3.0.6->apache-airflow)\n  Downloading wirerope-1.0.0-py2.py3-none-any.whl.metadata (3.3 kB)\nCollecting opentelemetry-exporter-otlp-proto-grpc==1.37.0 (from opentelemetry-exporter-otlp>=1.26.0->apache-airflow-core==3.0.6->apache-airflow)\n  Downloading opentelemetry_exporter_otlp_proto_grpc-1.37.0-py3-none-any.whl.metadata (2.4 kB)\nCollecting opentelemetry-exporter-otlp-proto-http==1.37.0 (from opentelemetry-exporter-otlp>=1.26.0->apache-airflow-core==3.0.6->apache-airflow)\n  Downloading opentelemetry_exporter_otlp_proto_http-1.37.0-py3-none-any.whl.metadata (2.3 kB)\nRequirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.37.0->opentelemetry-exporter-otlp>=1.26.0->apache-airflow-core==3.0.6->apache-airflow) (1.70.0)\nRequirement already satisfied: grpcio<2.0.0,>=1.63.2 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.37.0->opentelemetry-exporter-otlp>=1.26.0->apache-airflow-core==3.0.6->apache-airflow) (1.73.1)\nCollecting opentelemetry-exporter-otlp-proto-common==1.37.0 (from opentelemetry-exporter-otlp-proto-grpc==1.37.0->opentelemetry-exporter-otlp>=1.26.0->apache-airflow-core==3.0.6->apache-airflow)\n  Downloading opentelemetry_exporter_otlp_proto_common-1.37.0-py3-none-any.whl.metadata (1.8 kB)\nCollecting opentelemetry-proto==1.37.0 (from opentelemetry-exporter-otlp-proto-grpc==1.37.0->opentelemetry-exporter-otlp>=1.26.0->apache-airflow-core==3.0.6->apache-airflow)\n  Downloading opentelemetry_proto-1.37.0-py3-none-any.whl.metadata (2.3 kB)\nCollecting opentelemetry-sdk~=1.37.0 (from opentelemetry-exporter-otlp-proto-grpc==1.37.0->opentelemetry-exporter-otlp>=1.26.0->apache-airflow-core==3.0.6->apache-airflow)\n  Downloading opentelemetry_sdk-1.37.0-py3-none-any.whl.metadata (1.5 kB)\nCollecting protobuf<7.0,>=5.0 (from opentelemetry-proto==1.37.0->opentelemetry-exporter-otlp-proto-grpc==1.37.0->opentelemetry-exporter-otlp>=1.26.0->apache-airflow-core==3.0.6->apache-airflow)\n  Downloading protobuf-6.32.1-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\nRequirement already satisfied: tzdata>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pendulum<4.0,>=2.1.2->apache-airflow-core==3.0.6->apache-airflow) (2025.2)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.11.0->apache-airflow-core==3.0.6->apache-airflow) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.11.0->apache-airflow-core==3.0.6->apache-airflow) (2.33.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7.0->apache-airflow-core==3.0.6->apache-airflow) (1.17.0)\nRequirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.11/dist-packages (from python-slugify>=5.0->apache-airflow-core==3.0.6->apache-airflow) (1.3)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.31.0->apache-airflow-core==3.0.6->apache-airflow) (3.4.2)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.31.0->apache-airflow-core==3.0.6->apache-airflow) (2.5.0)\nCollecting types-requests (from retryhttp!=1.3.0,>=1.2.0->apache-airflow-task-sdk<1.1.0,>=1.0.6->apache-airflow)\n  Downloading types_requests-2.32.4.20250913-py3-none-any.whl.metadata (2.0 kB)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.6.0->apache-airflow-core==3.0.6->apache-airflow) (3.0.0)\nRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy<2.0,>=1.4.49->sqlalchemy[asyncio]<2.0,>=1.4.49->apache-airflow-core==3.0.6->apache-airflow) (3.2.3)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=41.0.0->apache-airflow-core==3.0.6->apache-airflow) (2.22)\nRequirement already satisfied: dnspython>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from email-validator>=2.0.0->fastapi[standard]!=0.115.10,>=0.115.0->apache-airflow-core==3.0.6->apache-airflow) (2.7.0)\nRequirement already satisfied: typer>=0.15.1 in /usr/local/lib/python3.11/dist-packages (from fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]!=0.115.10,>=0.115.0->apache-airflow-core==3.0.6->apache-airflow) (0.16.0)\nCollecting rich-toolkit>=0.14.8 (from fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]!=0.115.10,>=0.115.0->apache-airflow-core==3.0.6->apache-airflow)\n  Downloading rich_toolkit-0.15.1-py3-none-any.whl.metadata (1.0 kB)\nCollecting fastapi-cloud-cli>=0.1.1 (from fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]!=0.115.10,>=0.115.0->apache-airflow-core==3.0.6->apache-airflow)\n  Downloading fastapi_cloud_cli-0.1.5-py3-none-any.whl.metadata (3.2 kB)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=13.6.0->apache-airflow-core==3.0.6->apache-airflow) (0.1.2)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.0->apache-airflow-core==3.0.6->apache-airflow) (1.3.1)\nCollecting httptools>=0.6.3 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]!=0.115.10,>=0.115.0->apache-airflow-core==3.0.6->apache-airflow)\n  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\nCollecting python-dotenv>=0.13 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]!=0.115.10,>=0.115.0->apache-airflow-core==3.0.6->apache-airflow)\n  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\nCollecting uvloop>=0.15.1 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]!=0.115.10,>=0.115.0->apache-airflow-core==3.0.6->apache-airflow)\n  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\nCollecting watchfiles>=0.13 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]!=0.115.10,>=0.115.0->apache-airflow-core==3.0.6->apache-airflow)\n  Downloading watchfiles-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\nRequirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]!=0.115.10,>=0.115.0->apache-airflow-core==3.0.6->apache-airflow) (15.0.1)\nCollecting rignore>=0.5.1 (from fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]!=0.115.10,>=0.115.0->apache-airflow-core==3.0.6->apache-airflow)\n  Downloading rignore-0.6.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\nRequirement already satisfied: sentry-sdk>=2.20.0 in /usr/local/lib/python3.11/dist-packages (from fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]!=0.115.10,>=0.115.0->apache-airflow-core==3.0.6->apache-airflow) (2.31.0)\nCollecting opentelemetry-semantic-conventions==0.58b0 (from opentelemetry-sdk~=1.37.0->opentelemetry-exporter-otlp-proto-grpc==1.37.0->opentelemetry-exporter-otlp>=1.26.0->apache-airflow-core==3.0.6->apache-airflow)\n  Downloading opentelemetry_semantic_conventions-0.58b0-py3-none-any.whl.metadata (2.4 kB)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.15.1->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]!=0.115.10,>=0.115.0->apache-airflow-core==3.0.6->apache-airflow) (1.5.4)\nDownloading apache_airflow-3.0.6-py3-none-any.whl (12 kB)\nDownloading apache_airflow_core-3.0.6-py3-none-any.whl (3.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading apache_airflow_task_sdk-1.0.6-py3-none-any.whl (250 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.5/250.5 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading a2wsgi-1.10.10-py3-none-any.whl (17 kB)\nDownloading apache_airflow_providers_common_compat-1.7.3-py3-none-any.whl (30 kB)\nDownloading apache_airflow_providers_common_io-1.6.2-py3-none-any.whl (19 kB)\nDownloading apache_airflow_providers_common_sql-1.28.0-py3-none-any.whl (66 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading apache_airflow_providers_smtp-2.2.1-py3-none-any.whl (23 kB)\nDownloading apache_airflow_providers_standard-1.7.0-py3-none-any.whl (142 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading argcomplete-3.6.2-py3-none-any.whl (43 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading asgiref-3.9.1-py3-none-any.whl (23 kB)\nDownloading cadwyn-5.4.4-py3-none-any.whl (60 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.1/60.1 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading cron_descriptor-2.0.6-py3-none-any.whl (74 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.4/74.4 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading croniter-6.0.0-py2.py3-none-any.whl (25 kB)\nDownloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading lazy_object_proxy-1.12.0-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (68 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.8/68.8 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading libcst-1.8.4-cp311-cp311-manylinux_2_28_x86_64.whl (2.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading lockfile-0.12.2-py2.py3-none-any.whl (13 kB)\nDownloading methodtools-0.4.7-py2.py3-none-any.whl (4.0 kB)\nDownloading msgspec-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (210 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.7/210.7 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading opentelemetry_api-1.37.0-py3-none-any.whl (65 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.7/65.7 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading opentelemetry_exporter_otlp-1.37.0-py3-none-any.whl (7.0 kB)\nDownloading opentelemetry_exporter_otlp_proto_grpc-1.37.0-py3-none-any.whl (19 kB)\nDownloading opentelemetry_exporter_otlp_proto_http-1.37.0-py3-none-any.whl (19 kB)\nDownloading opentelemetry_exporter_otlp_proto_common-1.37.0-py3-none-any.whl (18 kB)\nDownloading opentelemetry_proto-1.37.0-py3-none-any.whl (72 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pathspec-0.12.1-py3-none-any.whl (31 kB)\nDownloading pendulum-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (353 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m353.7/353.7 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading python_daemon-3.1.2-py3-none-any.whl (30 kB)\nDownloading retryhttp-1.3.3-py3-none-any.whl (17 kB)\nDownloading rich_argparse-1.7.1-py3-none-any.whl (25 kB)\nDownloading SQLAlchemy-1.4.54-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading SQLAlchemy_JSONField-1.0.2-py3-none-any.whl (10 kB)\nDownloading sqlalchemy_utils-0.42.0-py3-none-any.whl (91 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.7/91.7 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading structlog-25.4.0-py3-none-any.whl (68 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.7/68.7 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading svcs-25.1.0-py3-none-any.whl (19 kB)\nDownloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading universal_pathlib-0.2.6-py3-none-any.whl (50 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading uuid6-2025.0.1-py3-none-any.whl (7.0 kB)\nDownloading fastapi_cli-0.0.11-py3-none-any.whl (11 kB)\nDownloading wirerope-1.0.0-py2.py3-none-any.whl (9.2 kB)\nDownloading types_requests-2.32.4.20250913-py3-none-any.whl (20 kB)\nDownloading fastapi_cloud_cli-0.1.5-py3-none-any.whl (18 kB)\nDownloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading opentelemetry_sdk-1.37.0-py3-none-any.whl (131 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.9/131.9 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading opentelemetry_semantic_conventions-0.58b0-py3-none-any.whl (207 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.0/208.0 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\nDownloading rich_toolkit-0.15.1-py3-none-any.whl (29 kB)\nDownloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m72.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading watchfiles-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (453 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m453.1/453.1 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading protobuf-6.32.1-cp39-abi3-manylinux2014_x86_64.whl (322 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.0/322.0 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading rignore-0.6.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (950 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m950.6/950.6 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: lockfile, wirerope, uvloop, uuid6, universal-pathlib, typing-extensions, types-requests, svcs, structlog, sqlalchemy, rignore, python-dotenv, python-daemon, protobuf, pathspec, msgspec, libcst, lazy-object-proxy, httptools, gunicorn, asgiref, argcomplete, a2wsgi, sqlalchemy-utils, sqlalchemy-jsonfield, pendulum, opentelemetry-proto, opentelemetry-api, methodtools, croniter, cron-descriptor, watchfiles, rich-toolkit, rich-argparse, opentelemetry-semantic-conventions, opentelemetry-exporter-otlp-proto-common, retryhttp, opentelemetry-sdk, opentelemetry-exporter-otlp-proto-http, opentelemetry-exporter-otlp-proto-grpc, fastapi-cloud-cli, fastapi-cli, cadwyn, opentelemetry-exporter-otlp, apache-airflow-providers-common-compat, apache-airflow-providers-standard, apache-airflow-providers-smtp, apache-airflow-providers-common-sql, apache-airflow-providers-common-io, apache-airflow-task-sdk, apache-airflow-core, apache-airflow\n  Attempting uninstall: typing-extensions\n    Found existing installation: typing_extensions 4.14.0\n    Uninstalling typing_extensions-4.14.0:\n      Successfully uninstalled typing_extensions-4.14.0\n  Attempting uninstall: sqlalchemy\n    Found existing installation: SQLAlchemy 2.0.41\n    Uninstalling SQLAlchemy-2.0.41:\n      Successfully uninstalled SQLAlchemy-2.0.41\n  Attempting uninstall: protobuf\n    Found existing installation: protobuf 3.20.3\n    Uninstalling protobuf-3.20.3:\n      Successfully uninstalled protobuf-3.20.3\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ngoogle-api-core 1.34.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5, but you have protobuf 6.32.1 which is incompatible.\ngoogle-cloud-translate 3.12.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 6.32.1 which is incompatible.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\npandas-gbq 0.29.1 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\nipython-sql 0.5.0 requires sqlalchemy>=2.0, but you have sqlalchemy 1.4.54 which is incompatible.\nibis-framework 9.5.0 requires toolz<1,>=0.11, but you have toolz 1.0.0 which is incompatible.\nthinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\ngoogle-ai-generativelanguage 0.6.15 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.32.1 which is incompatible.\npydrive2 1.21.3 requires cryptography<44, but you have cryptography 44.0.3 which is incompatible.\npydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.1.0 which is incompatible.\nlangchain-core 0.3.66 requires packaging<25,>=23.2, but you have packaging 25.0 which is incompatible.\ngoogle-cloud-storage 2.19.0 requires google-api-core<3.0.0dev,>=2.15.0, but you have google-api-core 1.34.1 which is incompatible.\ndataproc-spark-connect 0.7.5 requires google-api-core>=2.19, but you have google-api-core 1.34.1 which is incompatible.\ntensorflow 2.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.32.1 which is incompatible.\nbigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed a2wsgi-1.10.10 apache-airflow-3.0.6 apache-airflow-core-3.0.6 apache-airflow-providers-common-compat-1.7.3 apache-airflow-providers-common-io-1.6.2 apache-airflow-providers-common-sql-1.28.0 apache-airflow-providers-smtp-2.2.1 apache-airflow-providers-standard-1.7.0 apache-airflow-task-sdk-1.0.6 argcomplete-3.6.2 asgiref-3.9.1 cadwyn-5.4.4 cron-descriptor-2.0.6 croniter-6.0.0 fastapi-cli-0.0.11 fastapi-cloud-cli-0.1.5 gunicorn-23.0.0 httptools-0.6.4 lazy-object-proxy-1.12.0 libcst-1.8.4 lockfile-0.12.2 methodtools-0.4.7 msgspec-0.19.0 opentelemetry-api-1.37.0 opentelemetry-exporter-otlp-1.37.0 opentelemetry-exporter-otlp-proto-common-1.37.0 opentelemetry-exporter-otlp-proto-grpc-1.37.0 opentelemetry-exporter-otlp-proto-http-1.37.0 opentelemetry-proto-1.37.0 opentelemetry-sdk-1.37.0 opentelemetry-semantic-conventions-0.58b0 pathspec-0.12.1 pendulum-3.1.0 protobuf-6.32.1 python-daemon-3.1.2 python-dotenv-1.1.1 retryhttp-1.3.3 rich-argparse-1.7.1 rich-toolkit-0.15.1 rignore-0.6.4 sqlalchemy-1.4.54 sqlalchemy-jsonfield-1.0.2 sqlalchemy-utils-0.42.0 structlog-25.4.0 svcs-25.1.0 types-requests-2.32.4.20250913 typing-extensions-4.15.0 universal-pathlib-0.2.6 uuid6-2025.0.1 uvloop-0.21.0 watchfiles-1.1.0 wirerope-1.0.0\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# create airflow folder\nimport os\nos.environ[\"AIRFLOW_HOME\"] = \"/kaggle/working/airflow\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-17T01:55:15.728243Z","iopub.execute_input":"2025-09-17T01:55:15.728585Z","iopub.status.idle":"2025-09-17T01:55:15.733731Z","shell.execute_reply.started":"2025-09-17T01:55:15.728554Z","shell.execute_reply":"2025-09-17T01:55:15.732751Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# update database\n!airflow db migrate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-17T01:55:15.736629Z","iopub.execute_input":"2025-09-17T01:55:15.736927Z","iopub.status.idle":"2025-09-17T01:55:22.153529Z","shell.execute_reply.started":"2025-09-17T01:55:15.736906Z","shell.execute_reply":"2025-09-17T01:55:22.152161Z"}},"outputs":[{"name":"stdout","text":"[\u001b[34m2025-09-17T01:55:20.533+0000\u001b[0m] {\u001b[34mproviders_manager.py:\u001b[0m953} INFO\u001b[0m - The hook_class '\u001b[1mairflow.providers.standard.hooks.filesystem.FSHook\u001b[22m' is not fully initialized (UI widgets will be missing), because the 'flask_appbuilder' package is not installed, however it is not required for Airflow components to work\u001b[0m\n[\u001b[34m2025-09-17T01:55:20.535+0000\u001b[0m] {\u001b[34mproviders_manager.py:\u001b[0m953} INFO\u001b[0m - The hook_class '\u001b[1mairflow.providers.standard.hooks.package_index.PackageIndexHook\u001b[22m' is not fully initialized (UI widgets will be missing), because the 'flask_appbuilder' package is not installed, however it is not required for Airflow components to work\u001b[0m\nDB: sqlite:////kaggle/working/airflow/airflow.db\nPerforming upgrade to the metadata database sqlite:////kaggle/working/airflow/airflow.db\n[\u001b[34m2025-09-17T01:55:20.759+0000\u001b[0m] {\u001b[34mmigration.py:\u001b[0m211} INFO\u001b[0m - Context impl \u001b[1mSQLiteImpl\u001b[22m.\u001b[0m\n[\u001b[34m2025-09-17T01:55:20.760+0000\u001b[0m] {\u001b[34mmigration.py:\u001b[0m214} INFO\u001b[0m - Will assume \u001b[1mnon-transactional\u001b[22m DDL.\u001b[0m\n[\u001b[34m2025-09-17T01:55:20.761+0000\u001b[0m] {\u001b[34mmigration.py:\u001b[0m211} INFO\u001b[0m - Context impl \u001b[1mSQLiteImpl\u001b[22m.\u001b[0m\n[\u001b[34m2025-09-17T01:55:20.761+0000\u001b[0m] {\u001b[34mmigration.py:\u001b[0m214} INFO\u001b[0m - Will assume \u001b[1mnon-transactional\u001b[22m DDL.\u001b[0m\n[\u001b[34m2025-09-17T01:55:20.762+0000\u001b[0m] {\u001b[34mdb.py:\u001b[0m730} INFO\u001b[0m - Creating Airflow database tables from the ORM\u001b[0m\n[\u001b[34m2025-09-17T01:55:21.241+0000\u001b[0m] {\u001b[34mmigration.py:\u001b[0m211} INFO\u001b[0m - Context impl \u001b[1mSQLiteImpl\u001b[22m.\u001b[0m\n[\u001b[34m2025-09-17T01:55:21.242+0000\u001b[0m] {\u001b[34mmigration.py:\u001b[0m214} INFO\u001b[0m - Will assume \u001b[1mnon-transactional\u001b[22m DDL.\u001b[0m\n[\u001b[34m2025-09-17T01:55:21.274+0000\u001b[0m] {\u001b[34mmigration.py:\u001b[0m622} INFO\u001b[0m - Running \u001b[1mstamp_revision  -> fe199e1abd77\u001b[22m\u001b[0m\n[\u001b[34m2025-09-17T01:55:21.280+0000\u001b[0m] {\u001b[34mdb.py:\u001b[0m741} INFO\u001b[0m - Airflow database tables created\u001b[0m\nDatabase migrating done!\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"**Create standings_dag.py necessary for orchestration with Airflow---------------------------------------------------------------**","metadata":{}},{"cell_type":"code","source":"%%writefile standings_dag.py\nfrom airflow import DAG\nfrom airflow.providers.standard.operators.python import PythonOperator\nfrom datetime import timedelta, datetime \nimport pandas as pd \nimport json\nimport requests\nimport mysql.connector\nfrom kaggle_secrets import UserSecretsClient # enable kaggle secrets for this notebook to replace .env file\n\n\n# retrieve credentials to connect API\nAPI_KEY = UserSecretsClient().get_secret(\"API_KEY\")\nAPI_HOST = UserSecretsClient().get_secret(\"API_HOST\")\nurl = API_HOST\nheaders = {\"X-Auth-Token\": API_KEY}\n\n# retrieve credentials to connect to MySQL Server\nMYSQL_HOST = UserSecretsClient().get_secret(\"MYSQL_HOST\")\nMYSQL_PORT = UserSecretsClient().get_secret(\"MYSQL_PORT\")\nMYSQL_USER = UserSecretsClient().get_secret(\"MYSQL_USER\")\nMYSQL_PWD = UserSecretsClient().get_secret(\"MYSQL_PWD\")\nMYSQL_DB = UserSecretsClient().get_secret(\"MYSQL_DB\")\n\n# define extract_data() function\ndef extract_data():\n    print(\"fetching data from Football Data API\")\n    try:\n        response = requests.get(url, headers = headers)\n        response.raise_for_status() # raises an exception for http errors\n        print(\"API response received sucessfully\")\n        return response.json()\n    except requests.exceptions.RequestException as e:\n        print(f\"An error occured: {e}\")\n        raise\n\n# define transform_data() function\n# parse clubs records into a list of tuples\ndef transform_data():\n    data = extract_data()\n    standings_list = data[\"standings\"][0][\"table\"] # filter data down to the standings table list\n    rows = [] \n    for club in standings_list:\n        season = 2025\n        position = club[\"position\"]\n        team_id = club[\"team\"][\"id\"]\n        team = club[\"team\"][\"name\"]\n        played = club[\"playedGames\"]\n        won = club[\"won\"]\n        draw = club[\"draw\"]\n        lost = club[\"lost\"]\n        goals_for = club[\"goalsFor\"]\n        goals_against = club[\"goalsAgainst\"]\n        goal_diff = club[\"goalDifference\"]\n        points = club[\"points\"]\n        form = club[\"form\"]\n        club_records = (season, position, team_id, team, played, won, draw, lost, goals_for, goals_against, goal_diff, points, form)\n        rows.append(club_records)\n    return rows\n\n# define connect_to_db() function\ndef connect_to_db():\n    print(\"connect to MySQL database\")\n    try:\n        conn = mysql.connector.connect(\n            host = MYSQL_HOST,\n            port = MYSQL_PORT,\n            user = MYSQL_USER,\n            password = MYSQL_PWD,\n            database = MYSQL_DB,\n            ssl_ca = \"/kaggle/input/ca-cert/DigiCertGlobalRootG2.crt.pem\", ssl_disabled = False,\n            connection_timeout = 10, # process will stops after 10asec without a response\n            autocommit = False, # transactions are written in the database ONLY when we call a commit operation\n            raise_on_warnings = True # turns MySQL errors into python exceptions\n        )\n        if conn.is_connected():\n           print(f\"Connection to database successful!\") \n        return conn\n    except Error as e:\n        print(f\"Database connection failed: {e}\")\n        raise\n\n# define create_table() function\ndef create_table():\n    conn = connect_to_db()\n    print(\"Create table if not exist\")\n    try:\n        cursor = conn.cursor()\n        cursor.execute(\"\"\"\n        CREATE TABLE IF NOT EXISTS standings (\n        season INT NOT NULL,\n        position INT NOT NULL,\n        team_id INT NOT NULL,\n        team VARCHAR(100) NOT NULL,\n        played INT NOT NULL,\n        won INT NOT NULL,\n        draw INT NOT NULL,\n        lost INT NOT NULL,\n        goals_for INT NOT NULL,\n        goals_against INT NOT NULL,\n        goal_diff INT NOT NULL,\n        points INT NOT NULL,\n        form VARCHAR(5),\n        PRIMARY KEY (season, team_id),\n        UNIQUE KEY unique_season_pos(season, position)\n        );\n        \"\"\")\n        conn.commit()\n        print(\"Table was created\")\n    except Exception as e:\n        print(f\"Failed to create table: {e}\")\n\n# define upsert_records() function to update the standings table in MySQL database\ndef upsert_records():\n    UPSERT_SQL = \"\"\"INSERT INTO standings (season, position, team_id, team, played, won, draw, lost, goals_for, goals_against, goal_diff, points, form)\n    VALUES(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s) AS src\n    ON DUPLICATE KEY UPDATE\n    position = src.position,\n    team = src.team,\n    played = src.played,\n    won = src.won,\n    draw = src.draw,\n    lost = src.lost,\n    goals_for = src.goals_for,\n    goals_against = src.goals_against,\n    goal_diff = src.goal_diff,\n    points = src.points,\n    form = src.form\"\"\"\n    \n    data = transform_data()\n    conn = connect_to_db()\n    print(\"Insert and update standings results into the database\")\n    no_rows = len(data) # number of rows in the table\n    cursor = conn.cursor()\n    try:\n        cursor.executemany(UPSERT_SQL, data)\n        conn.commit()\n        print(f\"[SUCCESS] - Upsert completed for {no_rows} rows\")\n    except Exception as e:\n        conn.rollback()\n        print(f\"[ERROR] - Rolled back due to the following error: {e}\")\n    finally:\n        cursor.close()\n        conn.close()\n        print(\"\\nAll database connections closed. \\nClean up completed.\")\n\n# DAG settings\ndefaults_args= {\n    \"owner\": \"jnh\",\n    \"start_date\": datetime(2025, 9, 16),\n    \"depends_on_past\": False,\n    \"email_on_failure\": False,\n    \"email_on_retry\": False,\n    \"retries\": 1,\n    \"retries_delay\": timedelta(minutes = 5)\n}\nwith DAG(\"standings_dag\",\n        default_args = defaults_args,\n        catchup = False) as dag:\n        new_table = PythonOperator(\n        task_id = \"new_table\",\n        python_callable = create_table\n        )\n        load = PythonOperator(\n        task_id = \"load\",\n        python_callable = upsert_records\n        )\n        new_table>>load","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-17T04:11:03.850008Z","iopub.execute_input":"2025-09-17T04:11:03.850323Z","iopub.status.idle":"2025-09-17T04:11:03.858995Z","shell.execute_reply.started":"2025-09-17T04:11:03.850298Z","shell.execute_reply":"2025-09-17T04:11:03.858013Z"}},"outputs":[{"name":"stdout","text":"Overwriting standings_dag.py\n","output_type":"stream"}],"execution_count":79},{"cell_type":"code","source":"# create dags folder to host standings_dag.py\nfolder = \"dags\"\nfolder_path = os.path.join(\"/kaggle/working/airflow\", folder)\nos.makedirs(folder_path, exist_ok = True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-17T01:57:38.259903Z","iopub.execute_input":"2025-09-17T01:57:38.260178Z","iopub.status.idle":"2025-09-17T01:57:38.265107Z","shell.execute_reply.started":"2025-09-17T01:57:38.260158Z","shell.execute_reply":"2025-09-17T01:57:38.264118Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"import shutil\n# delete standings_dags in dags folder if exists\nif os.path.exists(\"/kaggle/working/airflow/dags/standings_dag.py\"):\n    os.remove(\"/kaggle/working/airflow/dags/standings_dag.py\")\n    print(\"file deleted\")\n\n# move standings_dag.py in dags folder\nshutil.move(\"/kaggle/working/standings_dag.py\", \"/kaggle/working/airflow/dags/standings_dag.py\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-17T04:11:11.375954Z","iopub.execute_input":"2025-09-17T04:11:11.376247Z","iopub.status.idle":"2025-09-17T04:11:11.383928Z","shell.execute_reply.started":"2025-09-17T04:11:11.376223Z","shell.execute_reply":"2025-09-17T04:11:11.383167Z"}},"outputs":[{"name":"stdout","text":"file deleted\n","output_type":"stream"},{"execution_count":80,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/airflow/dags/standings_dag.py'"},"metadata":{}}],"execution_count":80},{"cell_type":"code","source":"# test airflow DAG execution\n!airflow dags test standings_dag","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-17T04:11:15.499911Z","iopub.execute_input":"2025-09-17T04:11:15.500176Z","iopub.status.idle":"2025-09-17T04:11:25.406494Z","shell.execute_reply.started":"2025-09-17T04:11:15.500156Z","shell.execute_reply":"2025-09-17T04:11:25.405540Z"}},"outputs":[{"name":"stdout","text":"[\u001b[34m2025-09-17T04:11:18.228+0000\u001b[0m] {\u001b[34mproviders_manager.py:\u001b[0m953} INFO\u001b[0m - The hook_class '\u001b[1mairflow.providers.standard.hooks.filesystem.FSHook\u001b[22m' is not fully initialized (UI widgets will be missing), because the 'flask_appbuilder' package is not installed, however it is not required for Airflow components to work\u001b[0m\n[\u001b[34m2025-09-17T04:11:18.229+0000\u001b[0m] {\u001b[34mproviders_manager.py:\u001b[0m953} INFO\u001b[0m - The hook_class '\u001b[1mairflow.providers.standard.hooks.package_index.PackageIndexHook\u001b[22m' is not fully initialized (UI widgets will be missing), because the 'flask_appbuilder' package is not installed, however it is not required for Airflow components to work\u001b[0m\n[\u001b[34m2025-09-17T04:11:18.289+0000\u001b[0m] {\u001b[34mmanager.py:\u001b[0m122} INFO\u001b[0m - DAG bundles loaded: \u001b[1mdags-folder, example_dags\u001b[22m\u001b[0m\n[\u001b[34m2025-09-17T04:11:18.290+0000\u001b[0m] {\u001b[34mdagbag.py:\u001b[0m585} INFO\u001b[0m - Filling up the DagBag from \u001b[1m/kaggle/working/airflow/dags\u001b[22m\u001b[0m\n[\u001b[34m2025-09-17T04:11:18.529+0000\u001b[0m] {\u001b[34mutils.py:\u001b[0m164} INFO\u001b[0m - NumExpr defaulting to 4 threads.\u001b[0m\nNothing to clear.\n[\u001b[34m2025-09-17T04:11:19.598+0000\u001b[0m] {\u001b[34mdag.py:\u001b[0m2306} INFO\u001b[0m - created dagrun \u001b[1m<DagRun standings_dag @ 2025-09-17 04:11:18.289009+00:00: manual__2025-09-17T04:11:19.568681+00:00, state:running, queued_at: None. run_type: manual>\u001b[22m\u001b[0m\n[\u001b[34m2025-09-17T04:11:19.638+0000\u001b[0m] {\u001b[34mdag.py:\u001b[0m1230} INFO\u001b[0m - [DAG TEST] starting task_id=\u001b[1mnew_table\u001b[22m map_index=-1\u001b[0m\n[\u001b[34m2025-09-17T04:11:19.638+0000\u001b[0m] {\u001b[34mdag.py:\u001b[0m1233} INFO\u001b[0m - [DAG TEST] running task \u001b[1m<TaskInstance: standings_dag.new_table manual__2025-09-17T04:11:19.568681+00:00 [scheduled]>\u001b[22m\u001b[0m\n\u001b[2m2025-09-17 04:11:21\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mStarting task instance run    \u001b[0m \u001b[36mhostname\u001b[0m=\u001b[35mf36263b10085\u001b[0m \u001b[36mpid\u001b[0m=\u001b[35m328\u001b[0m \u001b[36mti_id\u001b[0m=\u001b[35m019955de-a8ae-7cc7-8451-a222277256aa\u001b[0m \u001b[36munixname\u001b[0m=\u001b[35mroot\u001b[0m\n\u001b[2m2025-09-17 04:11:21\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mRetrieved task instance details\u001b[0m \u001b[36mdag_id\u001b[0m=\u001b[35mstandings_dag\u001b[0m \u001b[36mstate\u001b[0m=\u001b[35mqueued\u001b[0m \u001b[36mtask_id\u001b[0m=\u001b[35mnew_table\u001b[0m \u001b[36mti_id\u001b[0m=\u001b[35m019955de-a8ae-7cc7-8451-a222277256aa\u001b[0m\n\u001b[2m2025-09-17 04:11:21\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mTask started                  \u001b[0m \u001b[36mhostname\u001b[0m=\u001b[35mf36263b10085\u001b[0m \u001b[36mprevious_state\u001b[0m=\u001b[35mqueued\u001b[0m \u001b[36mti_id\u001b[0m=\u001b[35m019955de-a8ae-7cc7-8451-a222277256aa\u001b[0m\n\u001b[2m2025-09-17 04:11:21\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mTask instance state updated   \u001b[0m \u001b[36mrows_affected\u001b[0m=\u001b[35m1\u001b[0m \u001b[36mti_id\u001b[0m=\u001b[35m019955de-a8ae-7cc7-8451-a222277256aa\u001b[0m\n[\u001b[34m2025-09-17T04:11:21.434+0000\u001b[0m] {\u001b[34m_client.py:\u001b[0m1025} INFO\u001b[0m - HTTP Request: \u001b[1mPATCH\u001b[22m \u001b[1mhttp://in-process.invalid./task-instances/019955de-a8ae-7cc7-8451-a222277256aa/run\u001b[22m \"\u001b[1mHTTP/1.1\u001b[22m 200 \u001b[1mOK\u001b[22m\"\u001b[0m\n\u001b[2m2025-09-17 04:11:21\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mSending request               \u001b[0m \u001b[36mmsg\u001b[0m=\u001b[35mSetRenderedFields(rendered_fields={'templates_dict': None, 'op_args': [], 'op_kwargs': {}}, type='SetRenderedFields')\u001b[0m\n\u001b[2m2025-09-17 04:11:21\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mReceived message from task runner\u001b[0m [\u001b[0m\u001b[1m\u001b[34msupervisor\u001b[0m]\u001b[0m \u001b[36mmsg\u001b[0m=\u001b[35mSetRenderedFields(rendered_fields={'templates_dict': None, 'op_args': [], 'op_kwargs': {}}, type='SetRenderedFields')\u001b[0m\n\u001b[2m2025-09-17 04:11:21\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mUpdating RenderedTaskInstanceFields\u001b[0m \u001b[36mfield_count\u001b[0m=\u001b[35m3\u001b[0m \u001b[36mti_id\u001b[0m=\u001b[35m019955de-a8ae-7cc7-8451-a222277256aa\u001b[0m\n\u001b[2m2025-09-17 04:11:21\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mRenderedTaskInstanceFields updated successfully\u001b[0m \u001b[36mti_id\u001b[0m=\u001b[35m019955de-a8ae-7cc7-8451-a222277256aa\u001b[0m\n[\u001b[34m2025-09-17T04:11:21.482+0000\u001b[0m] {\u001b[34m_client.py:\u001b[0m1025} INFO\u001b[0m - HTTP Request: \u001b[1mPUT\u001b[22m \u001b[1mhttp://in-process.invalid./task-instances/019955de-a8ae-7cc7-8451-a222277256aa/rtif\u001b[22m \"\u001b[1mHTTP/1.1\u001b[22m 201 \u001b[1mCreated\u001b[22m\"\u001b[0m\nTask instance is in running state\n Previous state of the Task instance: TaskInstanceState.QUEUED\nCurrent task name:new_table\nDag name:standings_dag\nconnect to MySQL database\n[\u001b[34m2025-09-17T04:11:21.667+0000\u001b[0m] {\u001b[34m__init__.py:\u001b[0m149} INFO\u001b[0m - package: \u001b[1mmysql.connector.plugins\u001b[22m\u001b[0m\n[\u001b[34m2025-09-17T04:11:21.667+0000\u001b[0m] {\u001b[34m__init__.py:\u001b[0m150} INFO\u001b[0m - plugin_name: \u001b[1mmysql_native_password\u001b[22m\u001b[0m\n[\u001b[34m2025-09-17T04:11:21.668+0000\u001b[0m] {\u001b[34m__init__.py:\u001b[0m154} INFO\u001b[0m - AUTHENTICATION_PLUGIN_CLASS: \u001b[1mMySQLNativePasswordAuthPlugin\u001b[22m\u001b[0m\nConnection to database successful!\nCreate table if not exist\nTable was created\n[2025-09-17 04:11:21,995] {python.py:218} INFO - Done. Returned value was: None\n[\u001b[34m2025-09-17T04:11:21.995+0000\u001b[0m] {\u001b[34mpython.py:\u001b[0m218} INFO\u001b[0m - Done. Returned value was: \u001b[1mNone\u001b[22m\u001b[0m\n\u001b[2m2025-09-17 04:11:21\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mSending request               \u001b[0m \u001b[36mmsg\u001b[0m=\u001b[35mSucceedTask(state='success', end_date=datetime.datetime(2025, 9, 17, 4, 11, 21, 995946, tzinfo=datetime.timezone.utc), task_outlets=[], outlet_events=[], rendered_map_index=None, type='SucceedTask')\u001b[0m\n\u001b[2m2025-09-17 04:11:21\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mReceived message from task runner\u001b[0m [\u001b[0m\u001b[1m\u001b[34msupervisor\u001b[0m]\u001b[0m \u001b[36mmsg\u001b[0m=\u001b[35mSucceedTask(state='success', end_date=datetime.datetime(2025, 9, 17, 4, 11, 21, 995946, tzinfo=datetime.timezone.utc), task_outlets=[], outlet_events=[], rendered_map_index=None, type='SucceedTask')\u001b[0m\n\u001b[2m2025-09-17 04:11:22\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mUpdating task instance state  \u001b[0m \u001b[36mnew_state\u001b[0m=\u001b[35msuccess\u001b[0m \u001b[36mti_id\u001b[0m=\u001b[35m019955de-a8ae-7cc7-8451-a222277256aa\u001b[0m\n\u001b[2m2025-09-17 04:11:22\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mRetrieved current task instance state\u001b[0m \u001b[36mmax_tries\u001b[0m=\u001b[35m1\u001b[0m \u001b[36mprevious_state\u001b[0m=\u001b[35mrunning\u001b[0m \u001b[36mti_id\u001b[0m=\u001b[35m019955de-a8ae-7cc7-8451-a222277256aa\u001b[0m \u001b[36mtry_number\u001b[0m=\u001b[35m1\u001b[0m\n\u001b[2m2025-09-17 04:11:22\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mTask instance state updated   \u001b[0m \u001b[36mnew_state\u001b[0m=\u001b[35msuccess\u001b[0m \u001b[36mrows_affected\u001b[0m=\u001b[35m1\u001b[0m \u001b[36mti_id\u001b[0m=\u001b[35m019955de-a8ae-7cc7-8451-a222277256aa\u001b[0m\n[\u001b[34m2025-09-17T04:11:22.036+0000\u001b[0m] {\u001b[34m_client.py:\u001b[0m1025} INFO\u001b[0m - HTTP Request: \u001b[1mPATCH\u001b[22m \u001b[1mhttp://in-process.invalid./task-instances/019955de-a8ae-7cc7-8451-a222277256aa/state\u001b[22m \"\u001b[1mHTTP/1.1\u001b[22m 204 \u001b[1mNo Content\u001b[22m\"\u001b[0m\n\u001b[2m2025-09-17 04:11:22\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mRunning finalizers            \u001b[0m [\u001b[0m\u001b[1m\u001b[34mtask\u001b[0m]\u001b[0m \u001b[36mti\u001b[0m=\u001b[35mRuntimeTaskInstance(id=UUID('019955de-a8ae-7cc7-8451-a222277256aa'), task_id='new_table', dag_id='standings_dag', run_id='manual__2025-09-17T04:11:19.568681+00:00', try_number=1, map_index=-1, hostname='f36263b10085', context_carrier=None, task=<Task(PythonOperator): new_table>, max_tries=1, start_date=datetime.datetime(2025, 9, 17, 4, 11, 20, 134030, tzinfo=datetime.timezone.utc), end_date=datetime.datetime(2025, 9, 17, 4, 11, 21, 995946, tzinfo=datetime.timezone.utc), state=<TaskInstanceState.SUCCESS: 'success'>, is_mapped=False, rendered_map_index=None, log_url=None)\u001b[0m\nTask instance in success state\n Previous state of the Task instance: TaskInstanceState.RUNNING\nTask operator:<Task(PythonOperator): new_table>\n[\u001b[34m2025-09-17T04:11:22.092+0000\u001b[0m] {\u001b[34mdag.py:\u001b[0m1230} INFO\u001b[0m - [DAG TEST] starting task_id=\u001b[1mload\u001b[22m map_index=-1\u001b[0m\n[\u001b[34m2025-09-17T04:11:22.092+0000\u001b[0m] {\u001b[34mdag.py:\u001b[0m1233} INFO\u001b[0m - [DAG TEST] running task \u001b[1m<TaskInstance: standings_dag.load manual__2025-09-17T04:11:19.568681+00:00 [scheduled]>\u001b[22m\u001b[0m\n\u001b[2m2025-09-17 04:11:23\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mStarting task instance run    \u001b[0m \u001b[36mhostname\u001b[0m=\u001b[35mf36263b10085\u001b[0m \u001b[36mpid\u001b[0m=\u001b[35m328\u001b[0m \u001b[36mti_id\u001b[0m=\u001b[35m019955de-a8af-743c-851a-b6023d9fb69f\u001b[0m \u001b[36munixname\u001b[0m=\u001b[35mroot\u001b[0m\n\u001b[2m2025-09-17 04:11:23\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mRetrieved task instance details\u001b[0m \u001b[36mdag_id\u001b[0m=\u001b[35mstandings_dag\u001b[0m \u001b[36mstate\u001b[0m=\u001b[35mqueued\u001b[0m \u001b[36mtask_id\u001b[0m=\u001b[35mload\u001b[0m \u001b[36mti_id\u001b[0m=\u001b[35m019955de-a8af-743c-851a-b6023d9fb69f\u001b[0m\n\u001b[2m2025-09-17 04:11:23\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mTask started                  \u001b[0m \u001b[36mhostname\u001b[0m=\u001b[35mf36263b10085\u001b[0m \u001b[36mprevious_state\u001b[0m=\u001b[35mqueued\u001b[0m \u001b[36mti_id\u001b[0m=\u001b[35m019955de-a8af-743c-851a-b6023d9fb69f\u001b[0m\n\u001b[2m2025-09-17 04:11:23\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mTask instance state updated   \u001b[0m \u001b[36mrows_affected\u001b[0m=\u001b[35m1\u001b[0m \u001b[36mti_id\u001b[0m=\u001b[35m019955de-a8af-743c-851a-b6023d9fb69f\u001b[0m\n[\u001b[34m2025-09-17T04:11:23.313+0000\u001b[0m] {\u001b[34m_client.py:\u001b[0m1025} INFO\u001b[0m - HTTP Request: \u001b[1mPATCH\u001b[22m \u001b[1mhttp://in-process.invalid./task-instances/019955de-a8af-743c-851a-b6023d9fb69f/run\u001b[22m \"\u001b[1mHTTP/1.1\u001b[22m 200 \u001b[1mOK\u001b[22m\"\u001b[0m\n\u001b[2m2025-09-17 04:11:23\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mSending request               \u001b[0m \u001b[36mmsg\u001b[0m=\u001b[35mSetRenderedFields(rendered_fields={'templates_dict': None, 'op_args': [], 'op_kwargs': {}}, type='SetRenderedFields')\u001b[0m\n\u001b[2m2025-09-17 04:11:23\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mReceived message from task runner\u001b[0m [\u001b[0m\u001b[1m\u001b[34msupervisor\u001b[0m]\u001b[0m \u001b[36mmsg\u001b[0m=\u001b[35mSetRenderedFields(rendered_fields={'templates_dict': None, 'op_args': [], 'op_kwargs': {}}, type='SetRenderedFields')\u001b[0m\n\u001b[2m2025-09-17 04:11:23\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mUpdating RenderedTaskInstanceFields\u001b[0m \u001b[36mfield_count\u001b[0m=\u001b[35m3\u001b[0m \u001b[36mti_id\u001b[0m=\u001b[35m019955de-a8af-743c-851a-b6023d9fb69f\u001b[0m\n\u001b[2m2025-09-17 04:11:23\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mRenderedTaskInstanceFields updated successfully\u001b[0m \u001b[36mti_id\u001b[0m=\u001b[35m019955de-a8af-743c-851a-b6023d9fb69f\u001b[0m\n[\u001b[34m2025-09-17T04:11:23.349+0000\u001b[0m] {\u001b[34m_client.py:\u001b[0m1025} INFO\u001b[0m - HTTP Request: \u001b[1mPUT\u001b[22m \u001b[1mhttp://in-process.invalid./task-instances/019955de-a8af-743c-851a-b6023d9fb69f/rtif\u001b[22m \"\u001b[1mHTTP/1.1\u001b[22m 201 \u001b[1mCreated\u001b[22m\"\u001b[0m\nTask instance is in running state\n Previous state of the Task instance: TaskInstanceState.QUEUED\nCurrent task name:load\nDag name:standings_dag\nfetching data from Football Data API\nAPI response received sucessfully\nconnect to MySQL database\nConnection to database successful!\nInsert and update standings results into the database\n[SUCCESS] - Upsert completed for 20 rows\n\nAll database connections closed. \nClean up completed.\n[2025-09-17 04:11:24,279] {python.py:218} INFO - Done. Returned value was: None\n[\u001b[34m2025-09-17T04:11:24.279+0000\u001b[0m] {\u001b[34mpython.py:\u001b[0m218} INFO\u001b[0m - Done. Returned value was: \u001b[1mNone\u001b[22m\u001b[0m\n\u001b[2m2025-09-17 04:11:24\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mSending request               \u001b[0m \u001b[36mmsg\u001b[0m=\u001b[35mSucceedTask(state='success', end_date=datetime.datetime(2025, 9, 17, 4, 11, 24, 280099, tzinfo=datetime.timezone.utc), task_outlets=[], outlet_events=[], rendered_map_index=None, type='SucceedTask')\u001b[0m\n\u001b[2m2025-09-17 04:11:24\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mReceived message from task runner\u001b[0m [\u001b[0m\u001b[1m\u001b[34msupervisor\u001b[0m]\u001b[0m \u001b[36mmsg\u001b[0m=\u001b[35mSucceedTask(state='success', end_date=datetime.datetime(2025, 9, 17, 4, 11, 24, 280099, tzinfo=datetime.timezone.utc), task_outlets=[], outlet_events=[], rendered_map_index=None, type='SucceedTask')\u001b[0m\n\u001b[2m2025-09-17 04:11:24\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mUpdating task instance state  \u001b[0m \u001b[36mnew_state\u001b[0m=\u001b[35msuccess\u001b[0m \u001b[36mti_id\u001b[0m=\u001b[35m019955de-a8af-743c-851a-b6023d9fb69f\u001b[0m\n\u001b[2m2025-09-17 04:11:24\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mRetrieved current task instance state\u001b[0m \u001b[36mmax_tries\u001b[0m=\u001b[35m1\u001b[0m \u001b[36mprevious_state\u001b[0m=\u001b[35mrunning\u001b[0m \u001b[36mti_id\u001b[0m=\u001b[35m019955de-a8af-743c-851a-b6023d9fb69f\u001b[0m \u001b[36mtry_number\u001b[0m=\u001b[35m1\u001b[0m\n\u001b[2m2025-09-17 04:11:24\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mTask instance state updated   \u001b[0m \u001b[36mnew_state\u001b[0m=\u001b[35msuccess\u001b[0m \u001b[36mrows_affected\u001b[0m=\u001b[35m1\u001b[0m \u001b[36mti_id\u001b[0m=\u001b[35m019955de-a8af-743c-851a-b6023d9fb69f\u001b[0m\n[\u001b[34m2025-09-17T04:11:24.308+0000\u001b[0m] {\u001b[34m_client.py:\u001b[0m1025} INFO\u001b[0m - HTTP Request: \u001b[1mPATCH\u001b[22m \u001b[1mhttp://in-process.invalid./task-instances/019955de-a8af-743c-851a-b6023d9fb69f/state\u001b[22m \"\u001b[1mHTTP/1.1\u001b[22m 204 \u001b[1mNo Content\u001b[22m\"\u001b[0m\n\u001b[2m2025-09-17 04:11:24\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mRunning finalizers            \u001b[0m [\u001b[0m\u001b[1m\u001b[34mtask\u001b[0m]\u001b[0m \u001b[36mti\u001b[0m=\u001b[35mRuntimeTaskInstance(id=UUID('019955de-a8af-743c-851a-b6023d9fb69f'), task_id='load', dag_id='standings_dag', run_id='manual__2025-09-17T04:11:19.568681+00:00', try_number=1, map_index=-1, hostname='f36263b10085', context_carrier=None, task=<Task(PythonOperator): load>, max_tries=1, start_date=datetime.datetime(2025, 9, 17, 4, 11, 22, 184852, tzinfo=datetime.timezone.utc), end_date=datetime.datetime(2025, 9, 17, 4, 11, 24, 280099, tzinfo=datetime.timezone.utc), state=<TaskInstanceState.SUCCESS: 'success'>, is_mapped=False, rendered_map_index=None, log_url=None)\u001b[0m\nTask instance in success state\n Previous state of the Task instance: TaskInstanceState.RUNNING\nTask operator:<Task(PythonOperator): load>\n[\u001b[34m2025-09-17T04:11:24.333+0000\u001b[0m] {\u001b[34mdagrun.py:\u001b[0m1180} INFO\u001b[0m - Marking run \u001b[1m<DagRun standings_dag @ 2025-09-17 04:11:18.289009+00:00: manual__2025-09-17T04:11:19.568681+00:00, state:running, queued_at: None. run_type: manual>\u001b[22m successful\u001b[0m\nDag run in success state\nDag run start:2025-09-17 04:11:18.289009+00:00 end:2025-09-17 04:11:24.333724+00:00\n[\u001b[34m2025-09-17T04:11:24.333+0000\u001b[0m] {\u001b[34mdagrun.py:\u001b[0m1238} INFO\u001b[0m - DagRun Finished: dag_id=\u001b[1mstandings_dag\u001b[22m, logical_date=\u001b[1m2025-09-17 04:11:18.289009+00:00\u001b[22m, run_id=\u001b[1mmanual__2025-09-17T04:11:19.568681+00:00\u001b[22m, run_start_date=\u001b[1m2025-09-17 04:11:18.289009+00:00\u001b[22m, run_end_date=\u001b[1m2025-09-17 04:11:24.333724+00:00\u001b[22m, run_duration=6.044715, state=\u001b[1msuccess\u001b[22m, run_type=\u001b[1mmanual\u001b[22m, data_interval_start=\u001b[1m2025-09-17 04:11:18.289009+00:00\u001b[22m, data_interval_end=\u001b[1m2025-09-17 04:11:18.289009+00:00\u001b[22m,\u001b[0m\n","output_type":"stream"}],"execution_count":81}]}